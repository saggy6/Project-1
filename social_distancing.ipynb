{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mature-stewart",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vivek Basant\\anaconda3\\envs\\final\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Vivek Basant\\anaconda3\\envs\\final\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Vivek Basant\\anaconda3\\envs\\final\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Vivek Basant\\anaconda3\\envs\\final\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Vivek Basant\\anaconda3\\envs\\final\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Vivek Basant\\anaconda3\\envs\\final\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import collections\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import PIL.ImageColor as ImageColor\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "import PIL.ImageFont as ImageFont\n",
    "import six\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from utils import label_map_util\n",
    "\n",
    "from utils import visualization_utils as vis_util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "average-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dcubic = []\n",
    "\n",
    "_TITLE_LEFT_MARGIN = 10\n",
    "_TITLE_TOP_MARGIN = 10\n",
    "STANDARD_COLORS = [\n",
    "    'AliceBlue', 'Chartreuse', 'Aqua', 'Aquamarine', 'Azure', 'Beige', 'Bisque',\n",
    "    'BlanchedAlmond', 'BlueViolet', 'BurlyWood', 'CadetBlue', 'AntiqueWhite',\n",
    "    'Chocolate', 'Coral', 'CornflowerBlue', 'Cornsilk', 'Crimson', 'Cyan',\n",
    "    'DarkCyan', 'DarkGoldenRod', 'DarkGrey', 'DarkKhaki', 'DarkOrange',\n",
    "    'DarkOrchid', 'DarkSalmon', 'DarkSeaGreen', 'DarkTurquoise', 'DarkViolet',\n",
    "    'DeepPink', 'DeepSkyBlue', 'DodgerBlue', 'FireBrick', 'FloralWhite',\n",
    "    'ForestGreen', 'Fuchsia', 'Gainsboro', 'GhostWhite', 'Gold', 'GoldenRod',\n",
    "    'Salmon', 'Tan', 'HoneyDew', 'HotPink', 'IndianRed', 'Ivory', 'Khaki',\n",
    "    'Lavender', 'LavenderBlush', 'LawnGreen', 'LemonChiffon', 'LightBlue',\n",
    "    'LightCoral', 'LightCyan', 'LightGoldenRodYellow', 'LightGray', 'LightGrey',\n",
    "    'LightGreen', 'LightPink', 'LightSalmon', 'LightSeaGreen', 'LightSkyBlue',\n",
    "    'LightSlateGray', 'LightSlateGrey', 'LightSteelBlue', 'LightYellow', 'Lime',\n",
    "    'LimeGreen', 'Linen', 'Magenta', 'MediumAquaMarine', 'MediumOrchid',\n",
    "    'MediumPurple', 'MediumSeaGreen', 'MediumSlateBlue', 'MediumSpringGreen',\n",
    "    'MediumTurquoise', 'MediumVioletRed', 'MintCream', 'MistyRose', 'Moccasin',\n",
    "    'NavajoWhite', 'OldLace', 'Olive', 'OliveDrab', 'Orange', 'OrangeRed',\n",
    "    'Orchid', 'PaleGoldenRod', 'PaleGreen', 'PaleTurquoise', 'PaleVioletRed',\n",
    "    'PapayaWhip', 'PeachPuff', 'Peru', 'Pink', 'Plum', 'PowderBlue', 'Purple',\n",
    "    'Red', 'RosyBrown', 'RoyalBlue', 'SaddleBrown', 'Green', 'SandyBrown',\n",
    "    'SeaGreen', 'SeaShell', 'Sienna', 'Silver', 'SkyBlue', 'SlateBlue',\n",
    "    'SlateGray', 'SlateGrey', 'Snow', 'SpringGreen', 'SteelBlue', 'GreenYellow',\n",
    "    'Teal', 'Thistle', 'Tomato', 'Turquoise', 'Violet', 'Wheat', 'White',\n",
    "    'WhiteSmoke', 'Yellow', 'YellowGreen'\n",
    "]\n",
    "\n",
    "\n",
    "def save_image_array_as_png(image, output_path):\n",
    "  \"\"\"Saves an image (represented as a numpy array) to PNG.\n",
    "  Args:\n",
    "    image: a numpy array with shape [height, width, 3].\n",
    "    output_path: path to which image should be written.\n",
    "  \"\"\"\n",
    "  image_pil = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "  with tf.gfile.Open(output_path, 'w') as fid:\n",
    "    image_pil.save(fid, 'PNG')\n",
    "\n",
    "\n",
    "def encode_image_array_as_png_str(image):\n",
    "  \"\"\"Encodes a numpy array into a PNG string.\n",
    "  Args:\n",
    "    image: a numpy array with shape [height, width, 3].\n",
    "  Returns:\n",
    "    PNG encoded image string.\n",
    "  \"\"\"\n",
    "  image_pil = Image.fromarray(np.uint8(image))\n",
    "  output = six.BytesIO()\n",
    "  image_pil.save(output, format='PNG')\n",
    "  png_string = output.getvalue()\n",
    "  output.close()\n",
    "  return png_string\n",
    "\n",
    "\n",
    "def draw_bounding_box_on_image_array(image,\n",
    "                                     ymin,\n",
    "                                     xmin,\n",
    "                                     ymax,\n",
    "                                     xmax,\n",
    "                                     color='red',\n",
    "                                     thickness=4,\n",
    "                                     display_str_list=(),\n",
    "                                     use_normalized_coordinates=True):\n",
    "  \"\"\"Adds a bounding box to an image (numpy array).\n",
    "  Args:\n",
    "    image: a numpy array with shape [height, width, 3].\n",
    "    ymin: ymin of bounding box in normalized coordinates (same below).\n",
    "    xmin: xmin of bounding box.\n",
    "    ymax: ymax of bounding box.\n",
    "    xmax: xmax of bounding box.\n",
    "    color: color to draw bounding box. Default is red.\n",
    "    thickness: line thickness. Default value is 4.\n",
    "    display_str_list: list of strings to display in box\n",
    "                      (each to be shown on its own line).\n",
    "    use_normalized_coordinates: If True (default), treat coordinates\n",
    "      ymin, xmin, ymax, xmax as relative to the image.  Otherwise treat\n",
    "      coordinates as absolute.\n",
    "  \"\"\"\n",
    "  image_pil = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "  draw_bounding_box_on_image(image_pil, ymin, xmin, ymax, xmax, color,\n",
    "                             thickness, display_str_list,\n",
    "                             use_normalized_coordinates)\n",
    "  np.copyto(image, np.array(image_pil))\n",
    "\n",
    "\n",
    "def draw_bounding_box_on_image(image,\n",
    "                               ymin,\n",
    "                               xmin,\n",
    "                               ymax,\n",
    "                               xmax,\n",
    "                               color='red',\n",
    "                               thickness=4,\n",
    "                               display_str_list=(),\n",
    "                               use_normalized_coordinates=True):\n",
    "  \"\"\"Adds a bounding box to an image.\n",
    "  Each string in display_str_list is displayed on a separate line above the\n",
    "  bounding box in black text on a rectangle filled with the input 'color'.\n",
    "  Args:\n",
    "    image: a PIL.Image object.\n",
    "    ymin: ymin of bounding box.\n",
    "    xmin: xmin of bounding box.\n",
    "    ymax: ymax of bounding box.\n",
    "    xmax: xmax of bounding box.\n",
    "    color: color to draw bounding box. Default is red.\n",
    "    thickness: line thickness. Default value is 4.\n",
    "    display_str_list: list of strings to display in box\n",
    "                      (each to be shown on its own line).\n",
    "    use_normalized_coordinates: If True (default), treat coordinates\n",
    "      ymin, xmin, ymax, xmax as relative to the image.  Otherwise treat\n",
    "      coordinates as absolute.\n",
    "  \"\"\"\n",
    "  draw = ImageDraw.Draw(image)\n",
    "  im_width, im_height = image.size\n",
    "  if use_normalized_coordinates:\n",
    "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                  ymin * im_height, ymax * im_height)\n",
    "  else:\n",
    "    (left, right, top, bottom) = (xmin, xmax, ymin, ymax)\n",
    "  draw.line([(left, top), (left, bottom), (right, bottom),\n",
    "             (right, top), (left, top)], width=thickness, fill=color)\n",
    "  #print(left,right,top,bottom)\n",
    "  try:\n",
    "    font = ImageFont.truetype('arial.ttf', 24)\n",
    "  except IOError:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "  text_bottom = top\n",
    "  # Reverse list and print from bottom to top.\n",
    "  for display_str in display_str_list[::-1]:\n",
    "    text_width, text_height = font.getsize(display_str)\n",
    "    margin = np.ceil(0.05 * text_height)\n",
    "    draw.rectangle(\n",
    "        [(left, text_bottom - text_height - 2 * margin), (left + text_width,\n",
    "                                                          text_bottom)],\n",
    "        fill=color)\n",
    "    draw.text(\n",
    "        (left + margin, text_bottom - text_height - margin),\n",
    "        display_str,\n",
    "        fill='black',\n",
    "        font=font)\n",
    "    text_bottom -= text_height - 2 * margin\n",
    "\n",
    "\n",
    "def draw_bounding_boxes_on_image_array(image,\n",
    "                                       boxes,\n",
    "                                       color='red',\n",
    "                                       thickness=4,\n",
    "                                       display_str_list_list=()):\n",
    "  \"\"\"Draws bounding boxes on image (numpy array).\n",
    "  Args:\n",
    "    image: a numpy array object.\n",
    "    boxes: a 2 dimensional numpy array of [N, 4]: (ymin, xmin, ymax, xmax).\n",
    "           The coordinates are in normalized format between [0, 1].\n",
    "    color: color to draw bounding box. Default is red.\n",
    "    thickness: line thickness. Default value is 4.\n",
    "    display_str_list_list: list of list of strings.\n",
    "                           a list of strings for each bounding box.\n",
    "                           The reason to pass a list of strings for a\n",
    "                           bounding box is that it might contain\n",
    "                           multiple labels.\n",
    "  Raises:\n",
    "    ValueError: if boxes is not a [N, 4] array\n",
    "  \"\"\"\n",
    "  image_pil = Image.fromarray(image)\n",
    "  draw_bounding_boxes_on_image(image_pil, boxes, color, thickness,\n",
    "                               display_str_list_list)\n",
    "  np.copyto(image, np.array(image_pil))\n",
    "\n",
    "\n",
    "def draw_bounding_boxes_on_image(image,\n",
    "                                 boxes,\n",
    "                                 color='red',\n",
    "                                 thickness=4,\n",
    "                                 display_str_list_list=()):\n",
    "  \"\"\"Draws bounding boxes on image.\n",
    "  Args:\n",
    "    image: a PIL.Image object.\n",
    "    boxes: a 2 dimensional numpy array of [N, 4]: (ymin, xmin, ymax, xmax).\n",
    "           The coordinates are in normalized format between [0, 1].\n",
    "    color: color to draw bounding box. Default is red.\n",
    "    thickness: line thickness. Default value is 4.\n",
    "    display_str_list_list: list of list of strings.\n",
    "                           a list of strings for each bounding box.\n",
    "                           The reason to pass a list of strings for a\n",
    "                           bounding box is that it might contain\n",
    "                           multiple labels.\n",
    "  Raises:\n",
    "    ValueError: if boxes is not a [N, 4] array\n",
    "  \"\"\"\n",
    "  boxes_shape = boxes.shape\n",
    "  if not boxes_shape:\n",
    "    return\n",
    "  if len(boxes_shape) != 2 or boxes_shape[1] != 4:\n",
    "    raise ValueError('Input must be of size [N, 4]')\n",
    "  for i in range(boxes_shape[0]):\n",
    "    display_str_list = ()\n",
    "    if display_str_list_list:\n",
    "      display_str_list = display_str_list_list[i]\n",
    "      \n",
    "    draw_bounding_box_on_image(image, boxes[i, 0], boxes[i, 1], boxes[i, 2],\n",
    "                               boxes[i, 3], color, thickness, display_str_list)\n",
    "\n",
    "\n",
    "def draw_keypoints_on_image_array(image,\n",
    "                                  keypoints,\n",
    "                                  color='red',\n",
    "                                  radius=2,\n",
    "                                  use_normalized_coordinates=True):\n",
    "  \"\"\"Draws keypoints on an image (numpy array).\n",
    "  Args:\n",
    "    image: a numpy array with shape [height, width, 3].\n",
    "    keypoints: a numpy array with shape [num_keypoints, 2].\n",
    "    color: color to draw the keypoints with. Default is red.\n",
    "    radius: keypoint radius. Default value is 2.\n",
    "    use_normalized_coordinates: if True (default), treat keypoint values as\n",
    "      relative to the image.  Otherwise treat them as absolute.\n",
    "  \"\"\"\n",
    "  image_pil = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "  draw_keypoints_on_image(image_pil, keypoints, color, radius,\n",
    "                          use_normalized_coordinates)\n",
    "  np.copyto(image, np.array(image_pil))\n",
    "\n",
    "\n",
    "def draw_keypoints_on_image(image,\n",
    "                            keypoints,\n",
    "                            color='red',\n",
    "                            radius=2,\n",
    "                            use_normalized_coordinates=True):\n",
    "  \"\"\"Draws keypoints on an image.\n",
    "  Args:\n",
    "    image: a PIL.Image object.\n",
    "    keypoints: a numpy array with shape [num_keypoints, 2].\n",
    "    color: color to draw the keypoints with. Default is red.\n",
    "    radius: keypoint radius. Default value is 2.\n",
    "    use_normalized_coordinates: if True (default), treat keypoint values as\n",
    "      relative to the image.  Otherwise treat them as absolute.\n",
    "  \"\"\"\n",
    "  draw = ImageDraw.Draw(image)\n",
    "  im_width, im_height = image.size\n",
    "  keypoints_x = [k[1] for k in keypoints]\n",
    "  keypoints_y = [k[0] for k in keypoints]\n",
    "  if use_normalized_coordinates:\n",
    "    keypoints_x = tuple([im_width * x for x in keypoints_x])\n",
    "    keypoints_y = tuple([im_height * y for y in keypoints_y])\n",
    "  for keypoint_x, keypoint_y in zip(keypoints_x, keypoints_y):\n",
    "    draw.ellipse([(keypoint_x - radius, keypoint_y - radius),\n",
    "                  (keypoint_x + radius, keypoint_y + radius)],\n",
    "                 outline=color, fill=color)\n",
    "\n",
    "\n",
    "def draw_mask_on_image_array(image, mask, color='red', alpha=0.7):\n",
    "  \"\"\"Draws mask on an image.\n",
    "  Args:\n",
    "    image: uint8 numpy array with shape (img_height, img_height, 3)\n",
    "    mask: a float numpy array of shape (img_height, img_height) with\n",
    "      values between 0 and 1\n",
    "    color: color to draw the keypoints with. Default is red.\n",
    "    alpha: transparency value between 0 and 1. (default: 0.7)\n",
    "  Raises:\n",
    "    ValueError: On incorrect data type for image or masks.\n",
    "  \"\"\"\n",
    "  if image.dtype != np.uint8:\n",
    "    raise ValueError('`image` not of type np.uint8')\n",
    "  if mask.dtype != np.float32:\n",
    "    raise ValueError('`mask` not of type np.float32')\n",
    "  if np.any(np.logical_or(mask > 1.0, mask < 0.0)):\n",
    "    raise ValueError('`mask` elements should be in [0, 1]')\n",
    "  rgb = ImageColor.getrgb(color)\n",
    "  pil_image = Image.fromarray(image)\n",
    "\n",
    "  solid_color = np.expand_dims(\n",
    "      np.ones_like(mask), axis=2) * np.reshape(list(rgb), [1, 1, 3])\n",
    "  pil_solid_color = Image.fromarray(np.uint8(solid_color)).convert('RGBA')\n",
    "  pil_mask = Image.fromarray(np.uint8(255.0*alpha*mask)).convert('L')\n",
    "  pil_image = Image.composite(pil_solid_color, pil_image, pil_mask)\n",
    "  np.copyto(image, np.array(pil_image.convert('RGB')))\n",
    "\n",
    "send = []\n",
    "\n",
    "def visualize_boxes_and_labels_on_image_array(image,\n",
    "                                              boxes,\n",
    "                                              classes,\n",
    "                                              scores,\n",
    "                                              category_index,\n",
    "                                              instance_masks=None,\n",
    "                                              keypoints=None,\n",
    "                                              use_normalized_coordinates=False,\n",
    "                                              max_boxes_to_draw=20,\n",
    "                                              min_score_thresh=.5,\n",
    "                                              agnostic_mode=False,\n",
    "                                              line_thickness=4):\n",
    "  \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\n",
    "  This function groups boxes that correspond to the same location\n",
    "  and creates a display string for each detection and overlays these\n",
    "  on the image.  Note that this function modifies the image array in-place\n",
    "  and does not return anything.\n",
    "  Args:\n",
    "    image: uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    boxes: a numpy array of shape [N, 4]\n",
    "    classes: a numpy array of shape [N]\n",
    "    scores: a numpy array of shape [N] or None.  If scores=None, then\n",
    "      this function assumes that the boxes to be plotted are groundtruth\n",
    "      boxes and plot all boxes as black with no classes or scores.\n",
    "    category_index: a dict containing category dictionaries (each holding\n",
    "      category index `id` and category name `name`) keyed by category indices.\n",
    "    instance_masks: a numpy array of shape [N, image_height, image_width], can\n",
    "      be None\n",
    "    keypoints: a numpy array of shape [N, num_keypoints, 2], can\n",
    "      be None\n",
    "    use_normalized_coordinates: whether boxes is to be interpreted as\n",
    "      normalized coordinates or not.\n",
    "    max_boxes_to_draw: maximum number of boxes to visualize.  If None, draw\n",
    "      all boxes.\n",
    "    min_score_thresh: minimum score threshold for a box to be visualized\n",
    "    agnostic_mode: boolean (default: False) controlling whether to evaluate in\n",
    "      class-agnostic mode or not.  This mode will display scores but ignore\n",
    "      classes.\n",
    "    line_thickness: integer (default: 4) controlling line width of the boxes.\n",
    "  \"\"\"\n",
    "  # Create a display string (and color) for every box location, group any boxes\n",
    "  # that correspond to the same location.\n",
    "  box_to_display_str_map = collections.defaultdict(list)\n",
    "  box_to_color_map = collections.defaultdict(str)\n",
    "  box_to_instance_masks_map = {}\n",
    "  box_to_keypoints_map = collections.defaultdict(list)\n",
    "  if not max_boxes_to_draw:\n",
    "    max_boxes_to_draw = boxes.shape[0]\n",
    " \n",
    "\n",
    "  #send = array([[0,0,0,0]])\n",
    "  send = []\n",
    "  color = {0 : (0,0,255), 1 : (0,255,0)}\n",
    "  dist = 0\n",
    "\n",
    "  for i in range(min(max_boxes_to_draw, boxes.shape[0])):\n",
    "    if scores is None or scores[i] > min_score_thresh:\n",
    "      box = tuple(boxes[i].tolist())\n",
    "      top=boxes[i,0]\n",
    "      left=boxes[i,1]\n",
    "      bottom=boxes[i,2]\n",
    "      right=boxes[i,3]\n",
    "      cx= ((right+left)/2)\n",
    "      cy= (bottom+top)/2\n",
    "      a = int((640*cx))\n",
    "      b = int(480*cy)\n",
    "      \n",
    "      send.append([a,b])\n",
    "    \n",
    "      if len(send) > 1 :\n",
    "            dist = int((((send[0][0] - send[1][0])**2) +((send[0][1]-send[1][1])**2) )**(.5))\n",
    "            if dist > 200 :\n",
    "                no_covid = 1\n",
    "            else:\n",
    "                no_covid = 0\n",
    "            cv2.line(image,(send[0][0],send[0][1]),(send[1][0],send[1][1]), color[no_covid], thickness = 3, lineType= 8 )\n",
    "    \n",
    "            \n",
    "      #print('Distance: '+ str(Distance)+' m')      \n",
    "      if instance_masks is not None:\n",
    "        box_to_instance_masks_map[box] = instance_masks[i]\n",
    "      if keypoints is not None:\n",
    "        box_to_keypoints_map[box].extend(keypoints[i])\n",
    "      if scores is None:\n",
    "        box_to_color_map[box] = 'black'\n",
    "      else:\n",
    "        if not agnostic_mode:\n",
    "          if classes[i] in category_index.keys():\n",
    "            class_name = category_index[classes[i]]['name']\n",
    "          else:\n",
    "            class_name = 'N/A'\n",
    "          display_str = '{}:{}:{}'.format(\n",
    "              a,b, dist)\n",
    "           #display_str = '{}'.format(dist)\n",
    "              #int(100*scores[i]),int((640*cx)),int((480*cy)))\n",
    "        else:\n",
    "          display_str = 'score: {}%'.format(int(100 * scores[i]))\n",
    "        box_to_display_str_map[box].append(display_str)\n",
    "        if agnostic_mode:\n",
    "          box_to_color_map[box] = 'DarkOrange'\n",
    "        else:\n",
    "          box_to_color_map[box] = STANDARD_COLORS[\n",
    "              classes[i] % len(STANDARD_COLORS)]\n",
    "\n",
    "  # Draw all boxes onto image.\n",
    "  for box, color in box_to_color_map.items():\n",
    "    ymin, xmin, ymax, xmax = box\n",
    "    #print(ymin)\n",
    "    if instance_masks is not None:\n",
    "      draw_mask_on_image_array(\n",
    "          image,\n",
    "          box_to_instance_masks_map[box],\n",
    "          color=color\n",
    "      )\n",
    "    draw_bounding_box_on_image_array(\n",
    "        image,\n",
    "        ymin,\n",
    "        xmin,\n",
    "        ymax,\n",
    "        xmax,\n",
    "        color=color,\n",
    "        thickness=line_thickness,\n",
    "        display_str_list=box_to_display_str_map[box],\n",
    "        use_normalized_coordinates=use_normalized_coordinates)\n",
    "    if keypoints is not None:\n",
    "      draw_keypoints_on_image_array(\n",
    "          image,\n",
    "          box_to_keypoints_map[box],\n",
    "          color=color,\n",
    "          radius=line_thickness / 2,\n",
    "          use_normalized_coordinates=use_normalized_coordinates)\n",
    "  return send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "transparent-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'ssd_mobilenet_v2_coco_2018_03_29'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "suburban-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fantastic-robinson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 90\n",
    "\n",
    "\n",
    "# ## Download Model\n",
    "\n",
    "if not os.path.exists(MODEL_NAME + '/frozen_inference_graph.pb'):\n",
    "\tprint ('Downloading the model')\n",
    "\topener = urllib.request.URLopener()\n",
    "\topener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "\ttar_file = tarfile.open(MODEL_FILE)\n",
    "\tfor file in tar_file.getmembers():\n",
    "\t  file_name = os.path.basename(file.name)\n",
    "\t  if 'frozen_inference_graph.pb' in file_name:\n",
    "\t    tar_file.extract(file, os.getcwd())\n",
    "\tprint ('Download complete')\n",
    "else:\n",
    "\tprint ('Model already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "joint-headset",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "recovered-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sixth-numbers",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecological-tampa",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-2845dffa12cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m       (boxes, scores, classes, num_detections) = sess.run(\n\u001b[0;32m     28\u001b[0m           \u001b[1;33m[\u001b[0m\u001b[0mboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_detections\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m           feed_dict={image_tensor: image_np_expanded})\n\u001b[0m\u001b[0;32m     30\u001b[0m       \u001b[1;31m# Visualization of the results of a detection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m       vivek = visualize_boxes_and_labels_on_image_array(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\final\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\final\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1120\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m             \u001b[0mnp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[1;32m~\\anaconda3\\envs\\final\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "#intializing the web camera device\n",
    "\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "# Running the tensorflow session\n",
    "with detection_graph.as_default():\n",
    "  with tf.Session(graph=detection_graph) as sess:\n",
    "   ret = True\n",
    "   while (ret):\n",
    "      ret,image_np = cap.read()\n",
    "      # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "      image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "      image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "      # Each box represents a part of the image where a particular object was detected.\n",
    "      boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "      # Each score represent how level of confidence for each of the objects.\n",
    "      # Score is shown on the result image, together with the class label.\n",
    "      scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "      classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "      num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "      # Actual detection.\n",
    "      (boxes, scores, classes, num_detections) = sess.run(\n",
    "          [boxes, scores, classes, num_detections],\n",
    "          feed_dict={image_tensor: image_np_expanded})\n",
    "      # Visualization of the results of a detection.\n",
    "      vivek = visualize_boxes_and_labels_on_image_array(\n",
    "          image_np,\n",
    "          np.squeeze(boxes),\n",
    "          np.squeeze(classes).astype(np.int32),\n",
    "          np.squeeze(scores),\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          line_thickness=8)\n",
    "      print(vivek)\n",
    "#      plt.figure(figsize=IMAGE_SIZE)\n",
    "#      plt.imshow(image_np)\n",
    "      cv2.imshow('image',cv2.resize(image_np,(1280,960)))\n",
    "      if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "          cv2.destroyAllWindows()\n",
    "          cap.release()\n",
    "          break\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-protection",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
